{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d3460ea-d4ee-498b-a20f-75e08f39a543",
   "metadata": {},
   "source": [
    "# Patent Kaggle challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070de716-458a-4f49-94d0-8ca516920361",
   "metadata": {},
   "source": [
    "notebook from fastai course lesson 4\n",
    "\n",
    "## Importing kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557ec44e-a70d-42a6-81bf-f76cf4242442",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -c us-patent-phrase-to-phrase-matching \n",
    "!unzip us-patent-phrase-to-phrase-matching.zip -d us-patent-phrase-to-phrase-matching\n",
    "!rm us-patent-phrase-to-phrase-matching.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfa1d2d5-1188-40a8-8867-9cdb5f3e45d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv  test.csv  train.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path = Path('us-patent-phrase-to-phrase-matching')\n",
    "!ls {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc7a072-c3df-470c-a7cd-5c0b7dd168f0",
   "metadata": {},
   "source": [
    "## Viewing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6223b80c-f7c0-46bd-98ec-868c40957437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement of pollution</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b9652b17b68b7a4</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act of abating</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36d72442aefd8232</td>\n",
       "      <td>abatement</td>\n",
       "      <td>active catalyst</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5296b0c19e1ce60e</td>\n",
       "      <td>abatement</td>\n",
       "      <td>eliminating process</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     anchor                  target context  score\n",
       "0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50\n",
       "1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75\n",
       "2  36d72442aefd8232  abatement         active catalyst     A47   0.25\n",
       "3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50\n",
       "4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(path/'train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac232236-a07c-46f3-8bb0-e5a7ea93daf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>36473</td>\n",
       "      <td>733</td>\n",
       "      <td>29340</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>8d135da0b55b8c88</td>\n",
       "      <td>component composite coating</td>\n",
       "      <td>composition</td>\n",
       "      <td>H01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>24</td>\n",
       "      <td>2186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                       anchor       target context\n",
       "count              36473                        36473        36473   36473\n",
       "unique             36473                          733        29340     106\n",
       "top     8d135da0b55b8c88  component composite coating  composition     H01\n",
       "freq                   1                          152           24    2186"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94c62f82-c3d3-46fe-b3c3-8bdb37888e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "composition               24\n",
       "motor                     22\n",
       "metal                     22\n",
       "data                      22\n",
       "assembly                  21\n",
       "                          ..\n",
       "switch over                1\n",
       "switch off valve           1\n",
       "switch control valve       1\n",
       "supply valve               1\n",
       "flow controlling valve     1\n",
       "Name: count, Length: 29340, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c65b3f67-aa6a-4d0b-aeb3-4063522f74e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "section\n",
       "B    8019\n",
       "H    6195\n",
       "G    6013\n",
       "C    5288\n",
       "A    4094\n",
       "F    4054\n",
       "E    1531\n",
       "D    1279\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['section'] = df.context.str[0]\n",
    "df.section.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14124be9-20a4-4b32-a198-1a9cfd17fcdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGdCAYAAADwjmIIAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAALulJREFUeJzt3Xt8VPWd//F3EjIToCQh8MhtjRh1lbsgKRgV6iUkCFqxVEVSZNsIVZOukH2AohgCqEgE5FpZVEQfGyraVZYCGzLCYhQil0hWbqKuVGzdCWu5DBBJhuT8/vCR+TGG28SZSc+X1/Px4FHnnM9853M+PUnej3NmkgjLsiwBAAAYJrK1GwAAAAgFQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEhtWruB1tTY2KhvvvlGHTp0UERERGu3AwAALoJlWTp+/LhSU1MVGXnu6zWXdMj55ptvlJaW1tptAACAFvj666912WWXnXP/JR1yOnToIOn7IcXGxgZtXa/Xq/LycmVnZys6Ojpo68Ifcw4fZh0ezDk8mHN4hHLOHo9HaWlpvp/j53JJh5ymW1SxsbFBDznt2rVTbGwsX0AhxJzDh1mHB3MOD+YcHuGY84XeasIbjwEAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACM1Ka1GwCAULniibWt3UJAnFGWSvq3dheAObiSAwAAjETIAQAARiLkAAAAIxFyAACAkQIOORUVFbrrrruUmpqqiIgIrVq1yrfP6/Xq8ccfV69evdS+fXulpqbqwQcf1DfffOO3xuHDh5Wbm6vY2FjFx8crLy9PJ06c8Kv55JNPNHDgQMXExCgtLU0lJSXNenn77bfVtWtXxcTEqFevXlq3bl2ghwMAAAwVcMg5efKkrrvuOi1evLjZvtraWn388cd6+umn9fHHH+udd97R/v379fOf/9yvLjc3V3v27JHL5dKaNWtUUVGhcePG+fZ7PB5lZ2erS5cuqqqq0gsvvKDi4mItXbrUV7NlyxY98MADysvL086dOzV8+HANHz5cu3fvDvSQAACAgQL+CPkdd9yhO+6446z74uLi5HK5/LYtWrRI/fv318GDB3X55Zdr3759Kisr0/bt25WRkSFJWrhwoYYOHarZs2crNTVVpaWlqq+v17Jly+RwONSjRw9VV1dr7ty5vjA0f/58DRkyRBMnTpQkzZgxQy6XS4sWLdKSJUsCPSwAAGCYkP+enGPHjikiIkLx8fGSpMrKSsXHx/sCjiRlZWUpMjJSW7du1T333KPKykoNGjRIDofDV5OTk6NZs2bpyJEj6tixoyorK1VYWOj3Wjk5OX63z36orq5OdXV1vscej0fS97fZvF5vEI5WvvXO/F+EBnMOH7vO2hlltXYLAXFGft+v3eZsN3Y9n+0mlHO+2DVDGnJOnTqlxx9/XA888IBiY2MlSW63W4mJif5NtGmjhIQEud1uX016erpfTVJSkm9fx44d5Xa7fdvOrGla42xmzpypadOmNdteXl6udu3aBX6AF/DDq1oIDeYcPnabtV1/sZ7d5mxXzDk8QjHn2trai6oLWcjxer267777ZFmWXnrppVC9TEAmT57sd/XH4/EoLS1N2dnZvhAWDF6vVy6XS4MHD1Z0dHTQ1oU/5hw+dp11z+L1rd1CQJyRlmZkNNpuznZj1/PZbkI556Y7MRcSkpDTFHC++uorbdy40S9AJCcn69ChQ371p0+f1uHDh5WcnOyrqamp8atpenyhmqb9Z+N0OuV0Opttj46ODsmJHqp14Y85h4/dZl3XENHaLbSI3eZsV8w5PEIx54tdL+i/J6cp4Hz++ed677331KlTJ7/9mZmZOnr0qKqqqnzbNm7cqMbGRg0YMMBXU1FR4XfPzeVy6dprr1XHjh19NRs2bPBb2+VyKTMzM9iHBAAAbCjgkHPixAlVV1erurpaknTgwAFVV1fr4MGD8nq9+uUvf6kdO3aotLRUDQ0Ncrvdcrvdqq+vlyR169ZNQ4YM0dixY7Vt2zZt3rxZBQUFGjlypFJTUyVJo0aNksPhUF5envbs2aOVK1dq/vz5freaHnvsMZWVlWnOnDn69NNPVVxcrB07dqigoCAIYwEAAHYXcMjZsWOH+vbtq759+0qSCgsL1bdvXxUVFemvf/2rVq9erb/85S/q06ePUlJSfP+2bNniW6O0tFRdu3bV7bffrqFDh+rmm2/2+x04cXFxKi8v14EDB9SvXz/9y7/8i4qKivx+l86NN96oFStWaOnSpbruuuv0xz/+UatWrVLPnj1/zDwAAIAhAn5Pzi233CLLOvfHMs+3r0lCQoJWrFhx3prevXvrgw8+OG/Nvffeq3vvvfeCrwcAAC49/O0qAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRQvpXyIFw6Fm83lZ/o+jPzw9r7RYA4JLAlRwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIwUccioqKnTXXXcpNTVVERERWrVqld9+y7JUVFSklJQUtW3bVllZWfr888/9ag4fPqzc3FzFxsYqPj5eeXl5OnHihF/NJ598ooEDByomJkZpaWkqKSlp1svbb7+trl27KiYmRr169dK6desCPRwAAGCogEPOyZMndd1112nx4sVn3V9SUqIFCxZoyZIl2rp1q9q3b6+cnBydOnXKV5Obm6s9e/bI5XJpzZo1qqio0Lhx43z7PR6PsrOz1aVLF1VVVemFF15QcXGxli5d6qvZsmWLHnjgAeXl5Wnnzp0aPny4hg8frt27dwd6SAAAwEBtAn3CHXfcoTvuuOOs+yzL0rx58zRlyhTdfffdkqQ33nhDSUlJWrVqlUaOHKl9+/aprKxM27dvV0ZGhiRp4cKFGjp0qGbPnq3U1FSVlpaqvr5ey5Ytk8PhUI8ePVRdXa25c+f6wtD8+fM1ZMgQTZw4UZI0Y8YMuVwuLVq0SEuWLGnRMAAAgDkCDjnnc+DAAbndbmVlZfm2xcXFacCAAaqsrNTIkSNVWVmp+Ph4X8CRpKysLEVGRmrr1q265557VFlZqUGDBsnhcPhqcnJyNGvWLB05ckQdO3ZUZWWlCgsL/V4/Jyen2e2zM9XV1amurs732OPxSJK8Xq+8Xu+PPXyfprWCuSaaa5qvM9Jq5U4CY8fzwq7ntDPKXudG07lstznbjV3PZ7sJ5Zwvds2ghhy32y1JSkpK8tuelJTk2+d2u5WYmOjfRJs2SkhI8KtJT09vtkbTvo4dO8rtdp/3dc5m5syZmjZtWrPt5eXlateu3cUcYkBcLlfQ10RzMzIaW7uFgNj5vWN2O6dL+rd2By1jtznbFXMOj1DMuba29qLqghpy/t5NnjzZ7+qPx+NRWlqasrOzFRsbG7TX8Xq9crlcGjx4sKKjo4O2Lvw1zfnpHZGqa4xo7XYu2u7inNZuIWB2Pad7Fq9v7RYC4oy0NCOj0XZzthu7ns92E8o5N92JuZCghpzk5GRJUk1NjVJSUnzba2pq1KdPH1/NoUOH/J53+vRpHT582Pf85ORk1dTU+NU0Pb5QTdP+s3E6nXI6nc22R0dHh+RED9W68FfXGKG6BvuEHDufE3Y7p+10XpzJbnO2K+YcHqGY88WuF9Tfk5Oenq7k5GRt2LDBt83j8Wjr1q3KzMyUJGVmZuro0aOqqqry1WzcuFGNjY0aMGCAr6aiosLvnpvL5dK1116rjh07+mrOfJ2mmqbXAQAAl7aAQ86JEydUXV2t6upqSd+/2bi6uloHDx5URESExo8fr2eeeUarV6/Wrl279OCDDyo1NVXDhw+XJHXr1k1DhgzR2LFjtW3bNm3evFkFBQUaOXKkUlNTJUmjRo2Sw+FQXl6e9uzZo5UrV2r+/Pl+t5oee+wxlZWVac6cOfr0009VXFysHTt2qKCg4MdPBQAA2F7At6t27NihW2+91fe4KXiMGTNGy5cv16RJk3Ty5EmNGzdOR48e1c0336yysjLFxMT4nlNaWqqCggLdfvvtioyM1IgRI7RgwQLf/ri4OJWXlys/P1/9+vVT586dVVRU5Pe7dG688UatWLFCU6ZM0ZNPPql//Md/1KpVq9SzZ88WDQIAAJgl4JBzyy23yLLO/bHMiIgITZ8+XdOnTz9nTUJCglasWHHe1+ndu7c++OCD89bce++9uvfee8/fMAAAuCTxt6sAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMFPSQ09DQoKefflrp6elq27atrrrqKs2YMUOWZflqLMtSUVGRUlJS1LZtW2VlZenzzz/3W+fw4cPKzc1VbGys4uPjlZeXpxMnTvjVfPLJJxo4cKBiYmKUlpamkpKSYB8OAACwqaCHnFmzZumll17SokWLtG/fPs2aNUslJSVauHChr6akpEQLFizQkiVLtHXrVrVv3145OTk6deqUryY3N1d79uyRy+XSmjVrVFFRoXHjxvn2ezweZWdnq0uXLqqqqtILL7yg4uJiLV26NNiHBAAAbKhNsBfcsmWL7r77bg0bNkySdMUVV+gPf/iDtm3bJun7qzjz5s3TlClTdPfdd0uS3njjDSUlJWnVqlUaOXKk9u3bp7KyMm3fvl0ZGRmSpIULF2ro0KGaPXu2UlNTVVpaqvr6ei1btkwOh0M9evRQdXW15s6d6xeGAADApSnoIefGG2/U0qVL9dlnn+maa67Rf//3f+vDDz/U3LlzJUkHDhyQ2+1WVlaW7zlxcXEaMGCAKisrNXLkSFVWVio+Pt4XcCQpKytLkZGR2rp1q+655x5VVlZq0KBBcjgcvpqcnBzNmjVLR44cUceOHZv1VldXp7q6Ot9jj8cjSfJ6vfJ6vUGbQdNawVwTzTXN1xlpXaDy74sdzwu7ntPOKHudG03nst3mbDd2PZ/tJpRzvtg1gx5ynnjiCXk8HnXt2lVRUVFqaGjQs88+q9zcXEmS2+2WJCUlJfk9LykpybfP7XYrMTHRv9E2bZSQkOBXk56e3myNpn1nCzkzZ87UtGnTmm0vLy9Xu3btWnK45+VyuYK+JpqbkdHY2i0EZN26da3dQovZ7Zwu6d/aHbSM3eZsV8w5PEIx59ra2ouqC3rIeeutt1RaWqoVK1b4biGNHz9eqampGjNmTLBfLiCTJ09WYWGh77HH41FaWpqys7MVGxsbtNfxer1yuVwaPHiwoqOjg7Yu/DXN+ekdkaprjGjtdi7a7uKc1m4hYHY9p3sWr2/tFgLijLQ0I6PRdnO2G7uez3YTyjk33Ym5kKCHnIkTJ+qJJ57QyJEjJUm9evXSV199pZkzZ2rMmDFKTk6WJNXU1CglJcX3vJqaGvXp00eSlJycrEOHDvmte/r0aR0+fNj3/OTkZNXU1PjVND1uqvkhp9Mpp9PZbHt0dHRITvRQrQt/dY0RqmuwT8ix8zlht3PaTufFmew2Z7tizuERijlf7HpB/3RVbW2tIiP9l42KilJj4/e3FNLT05WcnKwNGzb49ns8Hm3dulWZmZmSpMzMTB09elRVVVW+mo0bN6qxsVEDBgzw1VRUVPjdl3O5XLr22mvPeqsKAABcWoIecu666y49++yzWrt2rf785z/r3Xff1dy5c3XPPfdIkiIiIjR+/Hg988wzWr16tXbt2qUHH3xQqampGj58uCSpW7duGjJkiMaOHatt27Zp8+bNKigo0MiRI5WamipJGjVqlBwOh/Ly8rRnzx6tXLlS8+fP97sdBQAALl1Bv121cOFCPf3003r00Ud16NAhpaam6re//a2Kiop8NZMmTdLJkyc1btw4HT16VDfffLPKysoUExPjqyktLVVBQYFuv/12RUZGasSIEVqwYIFvf1xcnMrLy5Wfn69+/fqpc+fOKioq4uPjAABAUghCTocOHTRv3jzNmzfvnDURERGaPn26pk+ffs6ahIQErVix4ryv1bt3b33wwQctbRUAABiMv10FAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABgp6L8MEP9fz+L1tvoDgX9+flhrtwAAQNBwJQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkUIScv7617/qV7/6lTp16qS2bduqV69e2rFjh2+/ZVkqKipSSkqK2rZtq6ysLH3++ed+axw+fFi5ubmKjY1VfHy88vLydOLECb+aTz75RAMHDlRMTIzS0tJUUlISisMBAAA2FPSQc+TIEd10002Kjo7Wf/7nf2rv3r2aM2eOOnbs6KspKSnRggULtGTJEm3dulXt27dXTk6OTp065avJzc3Vnj175HK5tGbNGlVUVGjcuHG+/R6PR9nZ2erSpYuqqqr0wgsvqLi4WEuXLg32IQEAABtqE+wFZ82apbS0NL322mu+benp6b7/tixL8+bN05QpU3T33XdLkt544w0lJSVp1apVGjlypPbt26eysjJt375dGRkZkqSFCxdq6NChmj17tlJTU1VaWqr6+notW7ZMDodDPXr0UHV1tebOnesXhgAAwKUp6FdyVq9erYyMDN17771KTExU37599fLLL/v2HzhwQG63W1lZWb5tcXFxGjBggCorKyVJlZWVio+P9wUcScrKylJkZKS2bt3qqxk0aJAcDoevJicnR/v379eRI0eCfVgAAMBmgn4l58svv9RLL72kwsJCPfnkk9q+fbv++Z//WQ6HQ2PGjJHb7ZYkJSUl+T0vKSnJt8/tdisxMdG/0TZtlJCQ4Fdz5hWiM9d0u91+t8ea1NXVqa6uzvfY4/FIkrxer7xe7485bD9NazkjraCtGQ7BnEE4MOfwaerZbr07o+x1bjSdy3abs93Y9Xy2m1DO+WLXDHrIaWxsVEZGhp577jlJUt++fbV7924tWbJEY8aMCfbLBWTmzJmaNm1as+3l5eVq165d0F9vRkZj0NcMpXXr1rV2Cy3CnMPH5XK1dgsBKenf2h20jN3mbFfMOTxCMefa2tqLqgt6yElJSVH37t39tnXr1k3//u//LklKTk6WJNXU1CglJcVXU1NToz59+vhqDh065LfG6dOndfjwYd/zk5OTVVNT41fT9Lip5ocmT56swsJC32OPx6O0tDRlZ2crNjY20EM9J6/XK5fLpad3RKquMSJo64ba7uKc1m4hIMw5fJpmPXjwYEVHR7d2OxetZ/H61m4hIM5ISzMyGm03Z7ux6/lsN6Gcc9OdmAsJesi56aabtH//fr9tn332mbp06SLp+zchJycna8OGDb5Q4/F4tHXrVj3yyCOSpMzMTB09elRVVVXq16+fJGnjxo1qbGzUgAEDfDVPPfWUvF6vb3gul0vXXnvtWW9VSZLT6ZTT6Wy2PTo6OiQnel1jhOoa7PPD165f7Mw5fEL1tRIqdjovzmS3OdsVcw6PUMz5YtcL+huPJ0yYoI8++kjPPfecvvjiC61YsUJLly5Vfn6+JCkiIkLjx4/XM888o9WrV2vXrl168MEHlZqaquHDh0v6/srPkCFDNHbsWG3btk2bN29WQUGBRo4cqdTUVEnSqFGj5HA4lJeXpz179mjlypWaP3++35UaAABw6Qr6lZyf/vSnevfddzV58mRNnz5d6enpmjdvnnJzc301kyZN0smTJzVu3DgdPXpUN998s8rKyhQTE+OrKS0tVUFBgW6//XZFRkZqxIgRWrBggW9/XFycysvLlZ+fr379+qlz584qKiri4+MAAEBSCEKOJN1555268847z7k/IiJC06dP1/Tp089Zk5CQoBUrVpz3dXr37q0PPvigxX0CAABz8berAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARgp5yHn++ecVERGh8ePH+7adOnVK+fn56tSpk37yk59oxIgRqqmp8XvewYMHNWzYMLVr106JiYmaOHGiTp8+7VezadMmXX/99XI6nbr66qu1fPnyUB8OAACwiZCGnO3bt+tf//Vf1bt3b7/tEyZM0J/+9Ce9/fbbev/99/XNN9/oF7/4hW9/Q0ODhg0bpvr6em3ZskWvv/66li9frqKiIl/NgQMHNGzYMN16662qrq7W+PHj9dBDD2n9+vWhPCQAAGATIQs5J06cUG5url5++WV17NjRt/3YsWN69dVXNXfuXN12223q16+fXnvtNW3ZskUfffSRJKm8vFx79+7Vv/3bv6lPnz664447NGPGDC1evFj19fWSpCVLlig9PV1z5sxRt27dVFBQoF/+8pd68cUXQ3VIAADARtqEauH8/HwNGzZMWVlZeuaZZ3zbq6qq5PV6lZWV5dvWtWtXXX755aqsrNQNN9ygyspK9erVS0lJSb6anJwcPfLII9qzZ4/69u2ryspKvzWaas68LfZDdXV1qqur8z32eDySJK/XK6/X+2MP2adpLWekFbQ1wyGYMwgH5hw+TT3brXdnlL3OjaZz2W5z7llsryvozkhLMzLsN2e7CeX3jYtdMyQh580339THH3+s7du3N9vndrvlcDgUHx/vtz0pKUlut9tXc2bAadrftO98NR6PR999953atm3b7LVnzpypadOmNdteXl6udu3aXfwBXqQZGY1BXzOU1q1b19ottAhzDh+Xy9XaLQSkpH9rd9AyzDk87DZnuwrFnGtray+qLugh5+uvv9Zjjz0ml8ulmJiYYC//o0yePFmFhYW+xx6PR2lpacrOzlZsbGzQXsfr9crlcunpHZGqa4wI2rqhtrs4p7VbCAhzDp+mWQ8ePFjR0dGt3c5Fs+cVhkbmHGJ2nbPdhPL7RtOdmAsJesipqqrSoUOHdP311/u2NTQ0qKKiQosWLdL69etVX1+vo0eP+l3NqampUXJysiQpOTlZ27Zt81u36dNXZ9b88BNZNTU1io2NPetVHElyOp1yOp3NtkdHR4fkRK9rjFBdg31++Nr1i505h0+ovlZCxU7nxZmYc3jYbc52FYo5X+x6QX/j8e23365du3apurra9y8jI0O5ubm+/46OjtaGDRt8z9m/f78OHjyozMxMSVJmZqZ27dqlQ4cO+WpcLpdiY2PVvXt3X82ZazTVNK0BAAAubUG/ktOhQwf17NnTb1v79u3VqVMn3/a8vDwVFhYqISFBsbGx+t3vfqfMzEzdcMMNkqTs7Gx1795do0ePVklJidxut6ZMmaL8/HzflZiHH35YixYt0qRJk/Sb3/xGGzdu1FtvvaW1a9cG+5AAAIANhezTVefz4osvKjIyUiNGjFBdXZ1ycnL0+9//3rc/KipKa9as0SOPPKLMzEy1b99eY8aM0fTp03016enpWrt2rSZMmKD58+frsssu0yuvvKKcHPu93wEAAARfWELOpk2b/B7HxMRo8eLFWrx48Tmf06VLlwt+CuWWW27Rzp07g9EiAAAwDH+7CgAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEhBDzkzZ87UT3/6U3Xo0EGJiYkaPny49u/f71dz6tQp5efnq1OnTvrJT36iESNGqKamxq/m4MGDGjZsmNq1a6fExERNnDhRp0+f9qvZtGmTrr/+ejmdTl199dVavnx5sA8HAADYVNBDzvvvv6/8/Hx99NFHcrlc8nq9ys7O1smTJ301EyZM0J/+9Ce9/fbbev/99/XNN9/oF7/4hW9/Q0ODhg0bpvr6em3ZskWvv/66li9frqKiIl/NgQMHNGzYMN16662qrq7W+PHj9dBDD2n9+vXBPiQAAGBDbYK9YFlZmd/j5cuXKzExUVVVVRo0aJCOHTumV199VStWrNBtt90mSXrttdfUrVs3ffTRR7rhhhtUXl6uvXv36r333lNSUpL69OmjGTNm6PHHH1dxcbEcDoeWLFmi9PR0zZkzR5LUrVs3ffjhh3rxxReVk5MT7MMCAAA2E/SQ80PHjh2TJCUkJEiSqqqq5PV6lZWV5avp2rWrLr/8clVWVuqGG25QZWWlevXqpaSkJF9NTk6OHnnkEe3Zs0d9+/ZVZWWl3xpNNePHjz9nL3V1daqrq/M99ng8kiSv1yuv1/ujj7VJ01rOSCtoa4ZDMGcQDsw5fJp6tlvvzih7nRtN5zJzDi27ztluQvl942LXDGnIaWxs1Pjx43XTTTepZ8+ekiS32y2Hw6H4+Hi/2qSkJLndbl/NmQGnaX/TvvPVeDwefffdd2rbtm2zfmbOnKlp06Y1215eXq527dq17CDPY0ZGY9DXDKV169a1dgstwpzDx+VytXYLASnp39odtAxzDg+7zdmuQjHn2trai6oLacjJz8/X7t279eGHH4byZS7a5MmTVVhY6Hvs8XiUlpam7OxsxcbGBu11vF6vXC6Xnt4RqbrGiKCtG2q7i+11m485h0/TrAcPHqzo6OjWbuei9Sy213v0nJGWZmQ0MucQs+uc7SaU3zea7sRcSMhCTkFBgdasWaOKigpddtllvu3Jycmqr6/X0aNH/a7m1NTUKDk52Vezbds2v/WaPn11Zs0PP5FVU1Oj2NjYs17FkSSn0ymn09lse3R0dEhO9LrGCNU12OeHr12/2Jlz+ITqayVU7HRenIk5h4fd5mxXoZjzxa4X9E9XWZalgoICvfvuu9q4caPS09P99vfr10/R0dHasGGDb9v+/ft18OBBZWZmSpIyMzO1a9cuHTp0yFfjcrkUGxur7t27+2rOXKOppmkNAABwaQv6lZz8/HytWLFC//Ef/6EOHTr43kMTFxentm3bKi4uTnl5eSosLFRCQoJiY2P1u9/9TpmZmbrhhhskSdnZ2erevbtGjx6tkpISud1uTZkyRfn5+b4rMQ8//LAWLVqkSZMm6Te/+Y02btyot956S2vXrg32IQEAABsK+pWcl156SceOHdMtt9yilJQU37+VK1f6al588UXdeeedGjFihAYNGqTk5GS98847vv1RUVFas2aNoqKilJmZqV/96ld68MEHNX36dF9Nenq61q5dK5fLpeuuu05z5szRK6+8wsfHAQCApBBcybGsC3+UMCYmRosXL9bixYvPWdOlS5cLfgrllltu0c6dOwPuEQAAmI+/XQUAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACM1Ka1GwAAABd2xRNrW7uFgDijLJX0b90euJIDAACMRMgBAABGIuQAAAAjEXIAAICRCDkAAMBIhBwAAGAkQg4AADASIQcAABiJkAMAAIxEyAEAAEYi5AAAACMRcgAAgJEIOQAAwEiEHAAAYCRCDgAAMBIhBwAAGImQAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICRbB9yFi9erCuuuEIxMTEaMGCAtm3b1totAQCAvwO2DjkrV65UYWGhpk6dqo8//ljXXXedcnJydOjQodZuDQAAtDJbh5y5c+dq7Nix+vWvf63u3btryZIlateunZYtW9barQEAgFbWprUbaKn6+npVVVVp8uTJvm2RkZHKyspSZWXlWZ9TV1enuro63+Njx45Jkg4fPiyv1xu03rxer2pra9XGG6mGxoigrRtqf/vb31q7hYAw5/BpmvXf/vY3RUdHt3Y7F63N6ZOt3UJA2jRaqq1tZM4hxpzDI5RzPn78uCTJsqzz9xDUVw2jb7/9Vg0NDUpKSvLbnpSUpE8//fSsz5k5c6amTZvWbHt6enpIerSbznNau4NLA3PG+Yxq7QYuEcw5PEI95+PHjysuLu6c+20bclpi8uTJKiws9D1ubGzU4cOH1alTJ0VEBO9KgMfjUVpamr7++mvFxsYGbV34Y87hw6zDgzmHB3MOj1DO2bIsHT9+XKmpqeets23I6dy5s6KiolRTU+O3vaamRsnJyWd9jtPplNPp9NsWHx8fqhYVGxvLF1AYMOfwYdbhwZzDgzmHR6jmfL4rOE1s+8Zjh8Ohfv36acOGDb5tjY2N2rBhgzIzM1uxMwAA8PfAtldyJKmwsFBjxoxRRkaG+vfvr3nz5unkyZP69a9/3dqtAQCAVmbrkHP//ffr//7v/1RUVCS3260+ffqorKys2ZuRw83pdGrq1KnNbo0huJhz+DDr8GDO4cGcw+PvYc4R1oU+fwUAAGBDtn1PDgAAwPkQcgAAgJEIOQAAwEiEHAAAYCRCTgstXrxYV1xxhWJiYjRgwABt27btvPVvv/22unbtqpiYGPXq1Uvr1q0LU6f2FsicX375ZQ0cOFAdO3ZUx44dlZWVdcH/X/C9QM/nJm+++aYiIiI0fPjw0DZokEBnffToUeXn5yslJUVOp1PXXHMN3z8uQqBznjdvnq699lq1bdtWaWlpmjBhgk6dOhWmbu2poqJCd911l1JTUxUREaFVq1Zd8DmbNm3S9ddfL6fTqauvvlrLly8PbZMWAvbmm29aDofDWrZsmbVnzx5r7NixVnx8vFVTU3PW+s2bN1tRUVFWSUmJtXfvXmvKlClWdHS0tWvXrjB3bi+BznnUqFHW4sWLrZ07d1r79u2z/umf/smKi4uz/vKXv4S5c3sJdM5NDhw4YP3DP/yDNXDgQOvuu+8OT7M2F+is6+rqrIyMDGvo0KHWhx9+aB04cMDatGmTVV1dHebO7SXQOZeWllpOp9MqLS21Dhw4YK1fv95KSUmxJkyYEObO7WXdunXWU089Zb3zzjuWJOvdd989b/2XX35ptWvXziosLLT27t1rLVy40IqKirLKyspC1iMhpwX69+9v5efn+x43NDRYqamp1syZM89af99991nDhg3z2zZgwADrt7/9bUj7tLtA5/xDp0+ftjp06GC9/vrroWrRCC2Z8+nTp60bb7zReuWVV6wxY8YQci5SoLN+6aWXrCuvvNKqr68PV4tGCHTO+fn51m233ea3rbCw0LrppptC2qdJLibkTJo0yerRo4fftvvvv9/KyckJWV/crgpQfX29qqqqlJWV5dsWGRmprKwsVVZWnvU5lZWVfvWSlJOTc856tGzOP1RbWyuv16uEhIRQtWl7LZ3z9OnTlZiYqLy8vHC0aYSWzHr16tXKzMxUfn6+kpKS1LNnTz333HNqaGgIV9u205I533jjjaqqqvLd0vryyy+1bt06DR06NCw9Xypa42ehrX/jcWv49ttv1dDQ0Oy3KiclJenTTz8963PcbvdZ691ud8j6tLuWzPmHHn/8caWmpjb7osL/15I5f/jhh3r11VdVXV0dhg7N0ZJZf/nll9q4caNyc3O1bt06ffHFF3r00Ufl9Xo1derUcLRtOy2Z86hRo/Ttt9/q5ptvlmVZOn36tB5++GE9+eST4Wj5knGun4Uej0ffffed2rZtG/TX5EoOjPT888/rzTff1LvvvquYmJjWbscYx48f1+jRo/Xyyy+rc+fOrd2O8RobG5WYmKilS5eqX79+uv/++/XUU09pyZIlrd2aUTZt2qTnnntOv//97/Xxxx/rnXfe0dq1azVjxozWbg0/EldyAtS5c2dFRUWppqbGb3tNTY2Sk5PP+pzk5OSA6tGyOTeZPXu2nn/+eb333nvq3bt3KNu0vUDn/D//8z/685//rLvuusu3rbGxUZLUpk0b7d+/X1dddVVom7aplpzTKSkpio6OVlRUlG9bt27d5Ha7VV9fL4fDEdKe7aglc3766ac1evRoPfTQQ5KkXr166eTJkxo3bpyeeuopRUZyPSAYzvWzMDY2NiRXcSSu5ATM4XCoX79+2rBhg29bY2OjNmzYoMzMzLM+JzMz069eklwu1znr0bI5S1JJSYlmzJihsrIyZWRkhKNVWwt0zl27dtWuXbtUXV3t+/fzn/9ct956q6qrq5WWlhbO9m2lJef0TTfdpC+++MIXJCXps88+U0pKCgHnHFoy59ra2mZBpilYWvx5x6BplZ+FIXtLs8HefPNNy+l0WsuXL7f27t1rjRs3zoqPj7fcbrdlWZY1evRo64knnvDVb9682WrTpo01e/Zsa9++fdbUqVP5CPlFCHTOzz//vOVwOKw//vGP1v/+7//6/h0/fry1DsEWAp3zD/HpqosX6KwPHjxodejQwSooKLD2799vrVmzxkpMTLSeeeaZ1joEWwh0zlOnTrU6dOhg/eEPf7C+/PJLq7y83Lrqqqus++67r7UOwRaOHz9u7dy509q5c6clyZo7d661c+dO66uvvrIsy7KeeOIJa/To0b76po+QT5w40dq3b5+1ePFiPkL+92rhwoXW5ZdfbjkcDqt///7WRx995Nv3s5/9zBozZoxf/VtvvWVdc801lsPhsHr06GGtXbs2zB3bUyBz7tKliyWp2b+pU6eGv3GbCfR8PhMhJzCBznrLli3WgAEDLKfTaV155ZXWs88+a50+fTrMXdtPIHP2er1WcXGxddVVV1kxMTFWWlqa9eijj1pHjhwJf+M28l//9V9n/Z7bNNsxY8ZYP/vZz5o9p0+fPpbD4bCuvPJK67XXXgtpjxGWxbU4AABgHt6TAwAAjETIAQAARiLkAAAAIxFyAACAkQg5AADASIQcAABgJEIOAAAwEiEHAAAYiZADAACMRMgBAABGIuQAAAAjEXIAAICR/h9qH+XRIuxktAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.score.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93d6f3ee-5b18-4c28-95e6-0fdc5d73f2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>473137168ebf7484</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abating</td>\n",
       "      <td>F24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>621b048d70aa8867</td>\n",
       "      <td>absorbent properties</td>\n",
       "      <td>absorbent characteristics</td>\n",
       "      <td>D01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>bc20a1c961cb073a</td>\n",
       "      <td>absorbent properties</td>\n",
       "      <td>absorption properties</td>\n",
       "      <td>D01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>e955700dffd68624</td>\n",
       "      <td>acid absorption</td>\n",
       "      <td>absorption of acid</td>\n",
       "      <td>B08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>3a09aba546aac675</td>\n",
       "      <td>acid absorption</td>\n",
       "      <td>acid absorption</td>\n",
       "      <td>B08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36398</th>\n",
       "      <td>913141526432f1d6</td>\n",
       "      <td>wiring trough</td>\n",
       "      <td>wiring troughs</td>\n",
       "      <td>F16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36435</th>\n",
       "      <td>ee0746f2a8ecef97</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wood articles</td>\n",
       "      <td>B05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36440</th>\n",
       "      <td>ecaf479135cf0dfd</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden article</td>\n",
       "      <td>B05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36464</th>\n",
       "      <td>8ceaa2b5c2d56250</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wood article</td>\n",
       "      <td>B44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36468</th>\n",
       "      <td>8e1386cbefd7f245</td>\n",
       "      <td>wood article</td>\n",
       "      <td>wooden article</td>\n",
       "      <td>B44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1154 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                anchor                     target  \\\n",
       "28     473137168ebf7484             abatement                    abating   \n",
       "158    621b048d70aa8867  absorbent properties  absorbent characteristics   \n",
       "161    bc20a1c961cb073a  absorbent properties      absorption properties   \n",
       "311    e955700dffd68624       acid absorption         absorption of acid   \n",
       "315    3a09aba546aac675       acid absorption            acid absorption   \n",
       "...                 ...                   ...                        ...   \n",
       "36398  913141526432f1d6         wiring trough             wiring troughs   \n",
       "36435  ee0746f2a8ecef97          wood article              wood articles   \n",
       "36440  ecaf479135cf0dfd          wood article             wooden article   \n",
       "36464  8ceaa2b5c2d56250          wood article               wood article   \n",
       "36468  8e1386cbefd7f245          wood article             wooden article   \n",
       "\n",
       "      context  score section  \n",
       "28        F24    1.0       F  \n",
       "158       D01    1.0       D  \n",
       "161       D01    1.0       D  \n",
       "311       B08    1.0       B  \n",
       "315       B08    1.0       B  \n",
       "...       ...    ...     ...  \n",
       "36398     F16    1.0       F  \n",
       "36435     B05    1.0       B  \n",
       "36440     B05    1.0       B  \n",
       "36464     B44    1.0       B  \n",
       "36468     B44    1.0       B  \n",
       "\n",
       "[1154 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.score==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd4117e0-798b-42f1-a91a-11f510bf18e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    TEXT1: abatement; TEXT2: abatement of pollutio...\n",
       "1    TEXT1: abatement; TEXT2: act of abating; CONTE...\n",
       "2    TEXT1: abatement; TEXT2: active catalyst; CONT...\n",
       "3    TEXT1: abatement; TEXT2: eliminating process; ...\n",
       "4    TEXT1: abatement; TEXT2: forest region; CONTEX...\n",
       "Name: input, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['input'] = 'TEXT1: ' + df.anchor + '; TEXT2: ' + df.target + '; CONTEXT: ' + df.context\n",
    "df.input.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b8a88a-a392-4e43-995f-ee97b40b0d53",
   "metadata": {},
   "source": [
    "## Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd0514a0-c98b-4607-a11b-5655efbcd867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'anchor', 'target', 'context', 'labels', 'section', 'input'],\n",
       "    num_rows: 36473\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset,DatasetDict\n",
    "\n",
    "ds = Dataset.from_pandas(df)\n",
    "ds = ds.rename_columns({'score':'labels'})\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23e74873-ed94-43a8-9694-0166038ddce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nm = 'google-bert/bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db03be6f-627d-44f6-9483-ed3d8972f68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification,AutoTokenizer\n",
    "tokz = AutoTokenizer.from_pretrained(model_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf1de048-5957-4596-86da-2d20d79a83a7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['g',\n",
       " \"'\",\n",
       " 'day',\n",
       " 'folks',\n",
       " ',',\n",
       " 'i',\n",
       " \"'\",\n",
       " 'm',\n",
       " 'jeremy',\n",
       " 'from',\n",
       " 'fast',\n",
       " '.',\n",
       " 'ai',\n",
       " '!']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokz.tokenize(\"G'day folks, I'm Jeremy from fast.ai!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbca1ca6-67cb-422c-88b1-e91ceff7819a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'pl',\n",
       " '##at',\n",
       " '##yp',\n",
       " '##us',\n",
       " 'is',\n",
       " 'an',\n",
       " 'or',\n",
       " '##ni',\n",
       " '##thor',\n",
       " '##hy',\n",
       " '##nch',\n",
       " '##us',\n",
       " 'ana',\n",
       " '##tin',\n",
       " '##us',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokz.tokenize(\"A platypus is an ornithorhynchus anatinus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e10ae5b8-888e-49dd-ab9a-ac40a5d75d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30522\n",
      "1997\n"
     ]
    }
   ],
   "source": [
    "print(len(tokz.vocab))\n",
    "print(tokz.vocab['of'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39b4561d-8c65-4fba-b9b3-a96852f9b886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9601\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "print(ord('▁'))\n",
    "print(ord('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "753ba402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokz.all_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2543e2c3-208f-4f04-993b-ab369297cefd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SEP]'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sep = tokz.sep_token\n",
    "sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55d14fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    abatement[SEP]abatement of pollution[SEP]A47\n",
       "1            abatement[SEP]act of abating[SEP]A47\n",
       "2           abatement[SEP]active catalyst[SEP]A47\n",
       "3       abatement[SEP]eliminating process[SEP]A47\n",
       "4             abatement[SEP]forest region[SEP]A47\n",
       "Name: input, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['input'] = df.anchor + sep + df.target + sep + df.context\n",
    "df.input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc21c513-1544-4d23-a1f7-cfa018a71011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acfc76e87c89430dac21fd6e7366ea54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 36473\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tok_func(x): return tokz(x[\"input\"])\n",
    "tok_ds = ds.map(tok_func, batched=True, \n",
    "               remove_columns=('id', 'anchor', 'target', 'context', 'input', 'section'))\n",
    "tok_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f6bed94-0c2b-42a3-b08a-e30a79dd217b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': 0.5,\n",
       " 'input_ids': [101,\n",
       "  3793,\n",
       "  2487,\n",
       "  1024,\n",
       "  19557,\n",
       "  18532,\n",
       "  4765,\n",
       "  1025,\n",
       "  3793,\n",
       "  2475,\n",
       "  1024,\n",
       "  19557,\n",
       "  18532,\n",
       "  4765,\n",
       "  1997,\n",
       "  10796,\n",
       "  1025,\n",
       "  6123,\n",
       "  1024,\n",
       "  1037,\n",
       "  22610,\n",
       "  102],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e452757e-1eac-4c60-b6e2-c11d0a4494c4",
   "metadata": {},
   "source": [
    "Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18d07888-d490-4876-9826-b43e99425ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>36</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>4112d61851461f60</td>\n",
       "      <td>hybrid bearing</td>\n",
       "      <td>inorganic photoconductor drum</td>\n",
       "      <td>G02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id          anchor                         target  \\\n",
       "count                 36              36                             36   \n",
       "unique                36              34                             36   \n",
       "top     4112d61851461f60  hybrid bearing  inorganic photoconductor drum   \n",
       "freq                   1               2                              1   \n",
       "\n",
       "       context  \n",
       "count       36  \n",
       "unique      29  \n",
       "top        G02  \n",
       "freq         3  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pd.read_csv(path/'test.csv')\n",
    "eval_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee4fb7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93c0900c772c492baf6f8eeda9f0f723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_df['input'] = eval_df.anchor + sep + eval_df.target + sep + eval_df.context\n",
    "eval_ds = Dataset.from_pandas(eval_df).map(tok_func, batched=True, remove_columns=('id', 'anchor', 'target', 'context', 'input'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e33182-c29c-4f42-964a-ad250d254556",
   "metadata": {},
   "source": [
    "### Validation and Test data\n",
    "\n",
    "Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96967123-1101-45ca-bb51-b36143e913ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 27354\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 9119\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# method 1 : randomly pick items from the training data\n",
    "dds = tok_ds.train_test_split(0.25, seed=42)\n",
    "dds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5add5abd-5651-4c07-be72-ec4e59e1d415",
   "metadata": {},
   "source": [
    "method 2 : randomly select anchor values and pick all rows with this anchor values.\n",
    "\n",
    "This way, anchor values do not overlap btween validation and training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3b94f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['abatement', 'abnormal position', 'absorbent properties', 'acan',\n",
       "       'accept information', 'achieve authentication', 'acid absorption',\n",
       "       'ack', 'acoustooptic modulator', 'acrylate groups'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchors = df.anchor.unique()\n",
    "anchors[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e862db1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cervical support', 'rear adjustment',\n",
       "       'average power ratio reduction', 'output center', 'weldability',\n",
       "       'inner peripheral', 'contain bacterial cells', 'sawtooth waves',\n",
       "       'resilient spring clip', 'tunneling capacitor'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.shuffle(anchors)\n",
    "anchors[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12fd019b-77dc-4347-81b7-f040d58bd36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proportion of distinct anchor values in the validation dataset\n",
    "val_prop = 0.25\n",
    "\n",
    "# number of distinct anchor values in the validation dataset\n",
    "val_sz = int(len(anchors)*val_prop)\n",
    "\n",
    "# list of anchor values in the validation dataset\n",
    "val_anchors = anchors[:val_sz]\n",
    "\n",
    "# boolean variable indicating whether an observation corresponds to a validation anchor value\n",
    "is_val = df.anchor.isin(val_anchors)\n",
    "\n",
    "# lists of rows in the validation dataset and in the train dataset\n",
    "idxs = np.arange(len(df))\n",
    "val_idxs = idxs[is_val]\n",
    "trn_idxs = idxs[~is_val]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d8f5403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9204, 27269)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_idxs),len(trn_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c987c3ea-7d3b-48c7-a2b6-b08922bd53ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dds = DatasetDict({\"train\":tok_ds.select(trn_idxs),\n",
    "             \"test\": tok_ds.select(val_idxs)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d33dc5b4-e50f-438d-84c0-9c1f85990167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.36), np.float64(0.36))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[trn_idxs].score.mean().round(2), df.iloc[val_idxs].score.mean().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb303103-54fc-40f1-95f6-3d6be7e69b08",
   "metadata": {},
   "source": [
    "## Metric\n",
    "\n",
    "Transformers expect metrics to be returnes as a dictionnary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "de7862c1-62d4-4d86-8271-887511973871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def corr(x,y): return np.corrcoef(x,y)[0][1]\n",
    "def corr_d(eval_pred): return {'pearson': corr(*eval_pred)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034d3311-f6fd-461b-ab38-2ed19a648b34",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d87de4cb-be95-4d26-9b69-4ae443e6857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments,Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "80b3212b-725c-4805-8892-2f8237864628",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128\n",
    "epochs = 4\n",
    "lr = 8e-5\n",
    "wd = 0.01\n",
    "\n",
    "def get_trainer(dds):\n",
    "    args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n",
    "        eval_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n",
    "        num_train_epochs=epochs, weight_decay=wd, report_to='none')\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\n",
    "    \n",
    "    return Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n",
    "                   tokenizer=tokz, compute_metrics=corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c87420ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>=0.26.0'`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m args = \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43moutputs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcosine\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp16\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepoch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m*\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_to\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnone\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:134\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, torch_empty_cache_steps, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, include_for_metrics, eval_do_concat_batches, fp16_backend, evaluation_strategy, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, split_batches, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules, batch_eval_metrics, eval_on_start, use_liger_kernel, eval_use_gather_object, average_tokens_across_devices)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/transformers/training_args.py:1791\u001b[39m, in \u001b[36mTrainingArguments.__post_init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;66;03m# Initialize device before we proceed\u001b[39;00m\n\u001b[32m   1790\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.framework == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_torch_available():\n\u001b[32m-> \u001b[39m\u001b[32m1791\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m   1793\u001b[39m \u001b[38;5;66;03m# Disable average tokens when using single device\u001b[39;00m\n\u001b[32m   1794\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.average_tokens_across_devices:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/transformers/training_args.py:2313\u001b[39m, in \u001b[36mTrainingArguments.device\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2309\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2310\u001b[39m \u001b[33;03mThe device used by this process.\u001b[39;00m\n\u001b[32m   2311\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2312\u001b[39m requires_backends(\u001b[38;5;28mself\u001b[39m, [\u001b[33m\"\u001b[39m\u001b[33mtorch\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m2313\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setup_devices\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/transformers/utils/generic.py:62\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, obj, objtype)\u001b[39m\n\u001b[32m     60\u001b[39m cached = \u001b[38;5;28mgetattr\u001b[39m(obj, attr, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     cached = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(obj, attr, cached)\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cached\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/transformers/training_args.py:2186\u001b[39m, in \u001b[36mTrainingArguments._setup_devices\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[32m   2185\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[32m-> \u001b[39m\u001b[32m2186\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m   2187\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing the `Trainer` with `PyTorch` requires `accelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2188\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPlease run `pip install transformers[torch]` or `pip install \u001b[39m\u001b[33m'\u001b[39m\u001b[33maccelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2189\u001b[39m         )\n\u001b[32m   2190\u001b[39m \u001b[38;5;66;03m# We delay the init of `PartialState` to the end for clarity\u001b[39;00m\n\u001b[32m   2191\u001b[39m accelerator_state_kwargs = {\u001b[33m\"\u001b[39m\u001b[33menabled\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33muse_configured_state\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}\n",
      "\u001b[31mImportError\u001b[39m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>=0.26.0'`"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n",
    "        eval_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n",
    "        num_train_epochs=epochs, weight_decay=wd, report_to='none')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb71701",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\n",
    "    \n",
    "trainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n",
    "                   tokenizer=tokz, compute_metrics=corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e3857dc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>=0.26.0'`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m trainer = \u001b[43mget_trainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mget_trainer\u001b[39m\u001b[34m(dds)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_trainer\u001b[39m(dds):\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     args = \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43moutputs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarmup_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcosine\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp16\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepoch\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m*\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_to\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnone\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=\u001b[32m1\u001b[39m)\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Trainer(model, args, train_dataset=dds[\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m], eval_dataset=dds[\u001b[33m'\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     14\u001b[39m                    tokenizer=tokz, compute_metrics=corr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:134\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, torch_empty_cache_steps, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, include_for_metrics, eval_do_concat_batches, fp16_backend, evaluation_strategy, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, split_batches, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules, batch_eval_metrics, eval_on_start, use_liger_kernel, eval_use_gather_object, average_tokens_across_devices)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/transformers/training_args.py:1791\u001b[39m, in \u001b[36mTrainingArguments.__post_init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;66;03m# Initialize device before we proceed\u001b[39;00m\n\u001b[32m   1790\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.framework == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_torch_available():\n\u001b[32m-> \u001b[39m\u001b[32m1791\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m   1793\u001b[39m \u001b[38;5;66;03m# Disable average tokens when using single device\u001b[39;00m\n\u001b[32m   1794\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.average_tokens_across_devices:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/transformers/training_args.py:2313\u001b[39m, in \u001b[36mTrainingArguments.device\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2309\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2310\u001b[39m \u001b[33;03mThe device used by this process.\u001b[39;00m\n\u001b[32m   2311\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2312\u001b[39m requires_backends(\u001b[38;5;28mself\u001b[39m, [\u001b[33m\"\u001b[39m\u001b[33mtorch\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m2313\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setup_devices\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/transformers/utils/generic.py:62\u001b[39m, in \u001b[36mcached_property.__get__\u001b[39m\u001b[34m(self, obj, objtype)\u001b[39m\n\u001b[32m     60\u001b[39m cached = \u001b[38;5;28mgetattr\u001b[39m(obj, attr, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     cached = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(obj, attr, cached)\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cached\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/transformers/training_args.py:2186\u001b[39m, in \u001b[36mTrainingArguments._setup_devices\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[32m   2185\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[32m-> \u001b[39m\u001b[32m2186\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m   2187\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing the `Trainer` with `PyTorch` requires `accelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2188\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPlease run `pip install transformers[torch]` or `pip install \u001b[39m\u001b[33m'\u001b[39m\u001b[33maccelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2189\u001b[39m         )\n\u001b[32m   2190\u001b[39m \u001b[38;5;66;03m# We delay the init of `PartialState` to the end for clarity\u001b[39;00m\n\u001b[32m   2191\u001b[39m accelerator_state_kwargs = {\u001b[33m\"\u001b[39m\u001b[33menabled\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33muse_configured_state\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}\n",
      "\u001b[31mImportError\u001b[39m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>=0.26.0'`"
     ]
    }
   ],
   "source": [
    "trainer = get_trainer(dds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d7035f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate>=0.26.0 in /opt/conda/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.12/site-packages (from accelerate>=0.26.0) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from accelerate>=0.26.0) (24.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from accelerate>=0.26.0) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.12/site-packages (from accelerate>=0.26.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from accelerate>=0.26.0) (2.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.12/site-packages (from accelerate>=0.26.0) (0.29.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from accelerate>=0.26.0) (0.5.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2024.12.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (75.8.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.26.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.26.0) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install 'accelerate>=0.26.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e235629e-8f42-4124-8237-f075036024c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca26b922-b636-4973-82e7-5af80d78aac9",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bb70a8-6546-42d1-9cc0-09762f7c2fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = trainer.predict(eval_ds).predictions.astype(float)\n",
    "preds = np.clip(preds, 0, 1)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51515e6c-bae8-4acf-a710-d7a58c41e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "submission = datasets.Dataset.from_dict({\n",
    "    'id': eval_ds['id'],\n",
    "    'score': preds\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf246c4-a0fd-4651-b4c9-2606d5b929b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
